{
 "metadata": {
  "name": "2_Data_Prep"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "2 Data Prep"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Process data from Yahoo and other sources."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd\nimport numpy as np\nimport os as os\nimport pickle\nimport csv\ninlib = '/data/1_download'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/2_dataprep'",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Constituents Lists"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Read the ASX constituents list and ASX300 from csv\nasxlist = pd.read_csv(inlib+'/ASXListedCompanies.csv',skiprows=2)\nasxlist.columns=['company','symbol','GICS']\nasxlist.to_pickle(outlib+'/asxlist.p')\nasx300 = pd.read_csv(inlib+'/asx300.csv',skiprows=7,header=None)\nasx300 = asx300[[4,5]]\nasx300.columns=['symbol','company']\nasx300.to_pickle(outlib+'/asx300.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Yahoo Stock Data"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Function to process data\ndef processData(symbol,fileloc,GICS,stats):\n    '''Clean Yahoo csv stock data.'''    \n    #Read csv\n    temp = pd.read_csv(fileloc,parse_dates=[0],low_memory=False)\n    temp.rename(columns={'Date':'date',\n                         'Close':'close_'+symbol,\n                         'Volume':'volume_'+symbol,\n                         'Adj Close':'adjClose_'+symbol},inplace=True)\n    temp = temp[['date','close_'+symbol,'volume_'+symbol,'adjClose_'+symbol]]\n    \n    #Filter out older observations which were only recorded monthly\n    #Removes dates where the gap between the last observation is greater than 15\n    datemask = (temp['date'].shift() - temp['date']) < np.timedelta64(15,'D')\n    datemask[0] = True\n    temp = temp[datemask]\n    \n    #Attach GICS data\n    GICS_temp = GICS[GICS['symbol']==symbol]\n    temp['name_'+symbol] = GICS_temp['company'].values[0]\n    temp['GICS_'+symbol] = GICS_temp['GICS'].values[0]\n    \n    #Calculate volume in terms of cost\n    temp['volume_'+symbol] = temp[['volume_'+symbol,'close_'+symbol]].apply(lambda x: x[0]*x[1],axis=1)\n    \n    #Sort by date\n    temp.sort(['date'],inplace=True)\n    temp.index = range(temp.shape[0])\n    \n    #Calculate average volume over past 30 trading days\n    temp['z_vol_avg30_'+symbol] = pd.rolling_mean(temp['volume_'+symbol],window=30,min_periods=15).shift()\n    \n    #Calculate average closing price variation over the past 30 trading days\n    temp_chg = abs(temp['adjClose_'+symbol].shift() - temp['adjClose_'+symbol])\n    temp_chg_avg = pd.rolling_mean(temp_chg,window=30,min_periods=15).shift()\n    temp['z_varclose_avg30_'+symbol] = 1.0*temp_chg_avg/temp['adjClose_'+symbol].shift()\n    \n    #Append summary data stats\n    stats.append((symbol,\n                  temp['date'].min(),\n                  temp['date'].max(),\n                  temp['adjClose_'+symbol].map(lambda x: np.nan if x==0 else x).count(),\n                  temp['volume_'+symbol].map(lambda x: np.nan if x==0 else x).count(),\n                  (datemask == False).sum(),\n                  ((temp['date'].shift() - temp['date']) > np.timedelta64(7,'D')).sum()))\n    return temp",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Initialise summary statistics list\nstats = [('Symbol','First','Last','Num_AdjClose','Num_Volume','Removed','Date_Diff > 7')]",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\n#Process data\ni = 0\nsymbols = []\n\n#Loop across files in the data directory\nfor filename in os.listdir(inlib):\n    if len(filename)!=7 or filename[-4:]!='.csv': continue #Skip to next loop if not Yahoo csv\n    symbol = filename[:3]\n    symbols.append(symbol)\n    fileloc = inlib+'/'+filename\n    \n    #Process csv file\n    datatemp = processData(symbol,fileloc,asxlist,stats)\n    \n    #Merge all symbols into one large dataset\n    if i==0: data = datatemp.copy()\n    else: data = pd.merge(data,datatemp,how='outer',on=['date'])\n    i = i+1\n    \n    #Print progress to log and save temporary file every 200 symbols\n    if i%200 == 0: \n        print i\n        data.to_pickle(worklib+'/data_'+str(i)+'.p')\n        \ndata.sort(['date'],inplace=True) #Sort by date\ndata.index = range(data.shape[0])\ndata = data[data['date'].map(lambda x: x.year >= 1999)] #Keep only dates greater than 1999\n\n#Output summary stats\noutstats = open(outlib+'/stats.csv','wb')\nwritecsv = csv.writer(outstats)\nfor elem in stats:\n    writecsv.writerow(elem)\noutstats.close()\n\n#Pickle final dataset\ndata.to_pickle(outlib+'/data.p')\npickle.dump(symbols,open(outlib+'/symbolList.p','wb'))",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Short-Position Reports "
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data = pd.read_pickle(outlib+'/data.p') #Read existing dataframe\nsymbolList = pd.read_pickle(outlib+'/symbolList.p')\nsymbolList.append('date')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Function to process short sale data\ndef processShortSales(fileloc):\n    #Read data\n    temp = pd.read_csv(fileloc,skiprows=3)\n    symbol_list = temp[' Product Code'] #Get list of symbols\n    temp = temp.drop(['Product',' Product Code'],axis=1) \n    temp = temp.transpose()\n    #Rename columns based on symbol code\n    temp.columns = symbol_list.map(lambda x: 'shortsell_'+x[:-1] if x[-1]==' ' else 'shortsell_'+x)\n    \n    #List of dates\n    temp2 = pd.read_csv(fileloc,skiprows=1,nrows=1)\n    dates = [pd.to_datetime(col,format='%d/%m/%Y',dayfirst=True) for col in temp2.columns if col[0].isdigit()]\n    \n    #List of indices to keep\n    temp3 = pd.read_csv(fileloc,skiprows=2,nrows=1)\n    temp3 = temp3.drop([col for col in temp3.columns if col.startswith('Unnamed:')],axis=1)\n    mask = temp3.columns.map(lambda x: x.startswith('% of Total'))\n    \n    #Filter for relevant indices and reindex\n    temp = temp[mask]\n    temp['date'] = dates\n    temp.index = range(temp.shape[0])    \n    return temp",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Process short sale csv files\nss_files = ['ss_2010.csv','ss_2011.csv','ss_2012_2.csv','ss_2013_2.csv','ss_2014.csv','ss_current2.csv']\n\nfor i,ss_file in enumerate(ss_files):\n    if i==0: \n        ss_data = processShortSales(inlib+'/'+ss_file)\n    else:\n        ss_temp = processShortSales(inlib+'/'+ss_file)\n        ss_data = ss_data.append(ss_temp)\n\n#Remove stocks not in the symbol list\nss_data.drop([col for col in ss_data.columns if col[-3:] not in symbolList],axis=1)\nss_data.index = range(ss_data.shape[0])",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Merge to existing dataframe\ndata_ss = pd.merge(data,ss_data,how='left',on=['date'])\ndata_ss.to_pickle(outlib+'/data_ss.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Volume Rank"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data_ss = pd.read_pickle(outlib+'/data_ss.p') #Read existing dataframe\nsymbolList = pd.read_pickle(outlib+'/symbolList.p')\nsymbolList.append('date')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Rank companies based on average volume\nvolumes = data_ss[[col for col in data_ss.columns if col.startswith('z_vol_avg30_')]]\nvolRank = volumes.apply(lambda x: x.fillna(0).argsort().values[::-1].argsort(),axis=1)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Rename columns\nrenameList = {}\nfor col in volRank.columns:\n    renameList[col] = col.replace('z_vol_','z_volrank_')\n\nvolRank = volRank.rename(columns=renameList)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Merge to original data\ndata_ss_rank = pd.merge(data_ss,volRank,how='left',left_index=True,right_index=True)\ndata_ss_rank.to_pickle(outlib+'/data_ss_rank.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Split by Symbol"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data_ss_rank = pd.read_pickle(outlib+'/data_ss_rank.p')\nsymbolList = pd.read_pickle(outlib+'/symbolList.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Split data into individual symbol datasets\nfor symbol in symbolList:\n    #Required columns\n    cols = [col for col in data_ss_rank.columns if col.endswith('_'+symbol)] \n    cols.append('date')\n    \n    #Filter relevant columns and dates\n    temp = data_ss_rank[cols]    \n    temp = temp[temp['adjClose_'+symbol].map(lambda x: pd.isnull(x)==False)]\n    temp['symbol'] = symbol\n    \n    #Rename columns\n    renameList = {}\n    for var in cols:\n        if var != 'date': renameList[var] = var[:-len(symbol)-1]\n    temp = temp.rename(columns=renameList)        \n    \n    #Sort and reindex\n    temp.sort(['date'],inplace=True)\n    temp.index = range(temp.shape[0])\n    temp.to_pickle(outlib+'/symboldata/'+symbol+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    }
   ],
   "metadata": {}
  }
 ]
}