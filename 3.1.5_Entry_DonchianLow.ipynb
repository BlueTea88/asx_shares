{
 "metadata": {
  "name": "3.1.5_Entry_DonchianLow"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "3.1.5 Entry Signals - Donchian Low"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Simulate the Donchian Low entry signal - most liklely for short-selling."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#cp /data/2_dataprep/symboldata/* /scratch\n#chmod 777 /scratch",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom itertools import product\n#inlib = '/data/2_dataprep/symboldata'\ninlib = '/scratch'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/3_entry'\nsymbolList = pd.read_pickle('/data/2_dataprep/symbolList.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Entry Signal Functions"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Donchian Low entry signal\ndef entry_DonchianLow(data,p_low,p_pullback,p_days_pullback,\n                      price,variation):\n    '''\n    Outputs a dataset of dates and prices that triggered the Donchian Low signal.\n    \n    data: dataset containing historical prices for an individual stock\n    p_low: the number of days used to calculate the Donchian breakout criteria\n    p_pullback: pullback multiple of variation\n    p_days_pullback: number of days after the Donchian breakout for the pullback to be effective\n    price: price measure to consider (eg. adjClose, close)\n    variation: variation measure used to calculate pullback criteria\n    '''\n    temp = data.copy()\n    temp.sort(['date'],inplace=True)\n    temp.index = range(temp.shape[0])\n    temp['entry_date'] = np.nan\n    temp['entry_price'] = np.nan\n    temp['entry_'+price] = np.nan\n    \n    #Calculate Donchian cutoff\n    if len(temp) < p_low:\n        temp['__cutoff'] = np.nan #error trap number of obs < p_low\n    else:\n        temp['__cutoff'] = pd.rolling_min(temp[price],window=p_low,min_periods=p_low).shift()\n    \n    #Loop across dates that meet the Donchian cutoff\n    for i in temp[(temp[price] < temp['__cutoff'])].index:\n        #Check if the pullback criteria is met\n        pullback_criteria = temp.ix[i,price]*(1.0+p_pullback*temp.ix[i,variation])\n        check_pullback = temp.ix[i:(min(i+p_days_pullback,temp.shape[0]-1))]\n        check_pullback = check_pullback[check_pullback[price] > pullback_criteria]\n        if check_pullback.shape[0] > 0:\n            pullback_i = check_pullback.index[0]\n            temp.ix[i,'entry_date'] = temp.ix[pullback_i,'date']\n            temp.ix[i,'entry_price'] = temp.ix[pullback_i,'adjClose']\n            temp.ix[i,'entry_'+price] = temp.ix[pullback_i,price]\n    \n    #Cleanup\n    temp2 = temp.drop([col for col in temp.columns if col.startswith('__')],axis=1)\n    temp2 = temp2[temp2['entry_price']>0].drop_duplicates(['entry_date'])\n    temp2.sort(['entry_date'],inplace=True)\n    return temp2",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Calculate the performance of entry signals at various intervals\ndef entryPerformance(data,entry_data,transaction,intervals,shortsell):\n    '''\n    Attaches performance statistics at various intervals to the input entry_data dataset.\n    \n    data: dataset containing historical prices for an individual stock\n    entry_data: dataset containing entry trades for an individual stock\n    transaction: transaction cost percent for each trade\n    intervals: list of durations in days to compute performance metrics\n    shortsell: specifies whether to add or subtract transaction costs\n    '''\n    temp = entry_data.copy()\n    tempdata = data[['date','adjClose']].copy()\n    tempdata.sort(['date'],inplace=True)\n    tempdata.index = range(tempdata.shape[0])\n    max_date = tempdata['date'].max() #Latest date available\n    \n    #Add transaction costs if short-selling (negative returns are better)\n    if shortsell: \n        transaction_cost = -transaction\n    else:\n        transaction_cost = transaction\n    \n    #Initialise columns\n    for j in intervals:\n        temp['p_MFE_'+str(j)] = np.nan\n        temp['p_MAE_'+str(j)] = np.nan\n        temp['p_DER_'+str(j)] = np.nan\n    if temp.shape[0] == 0: return temp #Returns original dataset if no trades\n    \n    #Loop across entry trades and intervals\n    for i,j in product(temp.index,intervals):\n        entry_date = temp.ix[i,'entry_date']\n        entry_price = temp.ix[i,'entry_price']\n        final_date = entry_date + dt.timedelta(days=j) #Final date for performance evaluation\n        if final_date > max_date: continue #Skip to the next loop if not enough data\n        \n        #Subset data\n        temp_price = tempdata[(tempdata['date'] > entry_date) &\n                              (tempdata['date'] <= final_date)]        \n        if temp_price.shape[0]==0: continue #Prevents errors if there are gaps in data\n        \n        #Calculate maximum favourable/adverse execution\n        highest = temp_price['adjClose'].max()-(transaction_cost*entry_price)\n        lowest = temp_price['adjClose'].min()-(transaction_cost*entry_price)\n        temp.ix[i,'p_MFE_'+str(j)] = 365.25*np.log(highest/entry_price)/j\n        temp.ix[i,'p_MAE_'+str(j)] = 365.25*np.log(lowest/entry_price)/j\n        \n        #Calculate duration ending return\n        ending = temp_price.ix[temp_price.index[-1],'adjClose']-(transaction_cost*entry_price)\n        temp.ix[i,'p_DER_'+str(j)] = 365.25*np.log(ending/entry_price)/j    \n    return temp        ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Initialise Parallel Processing"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from IPython.parallel import Client\nrc = Client()\nl_view = rc.load_balanced_view()\nd_view = rc[:]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%px\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom itertools import product\nimport socket\nimport platform\n#inlib = '/data/2_dataprep/symboldata'\ninlib = '/scratch'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/3_entry'",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "d_view.push({'entry_DonchianLow':entry_DonchianLow,'entryPerformance':entryPerformance});\nfor i in rc.ids: #Identify machines\n    dv = rc[i]\n    dv.push({'machine_id':i})",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Score Entry Signals"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Function to score an individual symbol\ndef entryScore(fileloc,symbol,entryFunction,transaction,intervals,shortsell,outloc,**kwargs):\n    '''\n    Outputs triggered entry signals of an individual symbol and associated performance statistics.\n    \n    fileloc: location of file that contains the required individual company data\n    symbol: company to process\n    entryFunction: entry signal function\n    transaction: transaction costs as a percentage of each trade\n    intervals: durations to calculate performance metrics\n    outloc: location to store final dataset\n    '''\n    indata = pd.read_pickle(fileloc) #Read data\n    data1 = entryFunction(data=indata,**kwargs) #Find triggered entry signals\n    data2 = entryPerformance(indata,data1,transaction,intervals,shortsell) #Calculate performance statistics\n    data2.to_pickle(outloc) #Output final dataset\n    return machine_id #Check which machine processes this function",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian Low"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def inv_DonchianLow(label,p_low,p_pullback,p_days_pullback,price,variation,shortsell):    \n    #Loop across symbols and process in parallel\n    allResults = []\n    for i,symbol in enumerate(symbolList):\n        fileloc = inlib+'/'+symbol+'.p'\n        asyncResult = l_view.apply(entryScore,\n                                   fileloc=fileloc,symbol=symbol,\n                                   entryFunction=entry_DonchianLow,\n                                   transaction=0.01,intervals=[50,100,150,200,250,300,350,700,1050],\n                                   shortsell=shortsell,\n                                   outloc=worklib+'/'+label+'_'+symbol+'.p',\n                                   p_low=p_low,p_pullback=p_pullback,p_days_pullback=p_days_pullback,\n                                   price=price,variation=variation)\n        allResults.append((symbol,asyncResult))        \n    \n    #Check results and append final datasets\n    i = 0\n    for symbol,result in allResults:\n        try:\n            result_test = result.get()\n            if i==0: \n                final = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')                \n            else:\n                temp = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')\n                final = final.append(temp)                \n            i = i + 1\n            #if i%500 == 0: print i\n        except:\n            print 'Error processing symbol: '+symbol\n            pass\n    \n    #Output final dataset\n    final.to_pickle(outlib+'/'+label+'.p')\n    print 'Procesed: '+label",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\n#inv_DonchianLow('DonchianLow_350_0_30',350,0,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_300_0_30',300,0,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_250_0_30',250,0,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_200_0_30',200,0,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_150_0_30',150,0,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_350_3_30',350,3,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_300_3_30',300,3,30,'adjClose','z_varclose_avg30',True)\ninv_DonchianLow('DonchianLow_300_3_30_close',300,3,30,'close','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_250_3_30',250,3,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_200_3_30',200,3,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_150_3_30',150,3,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_350_3_60',350,3,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_300_3_60',300,3,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_250_3_60',250,3,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_200_3_60',200,3,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_150_3_60',150,3,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_350_5_30',350,5,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_300_5_30',300,5,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_250_5_30',250,5,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_200_5_30',200,5,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_150_5_30',150,5,30,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_350_5_60',350,5,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_300_5_60',300,5,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_250_5_60',250,5,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_200_5_60',200,5,60,'adjClose','z_varclose_avg30',True)\n#inv_DonchianLow('DonchianLow_150_5_60',150,5,60,'adjClose','z_varclose_avg30',True)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Procesed: DonchianLow_300_3_30_close\nCPU times: user 1min 32s, sys: 17.5 s, total: 1min 49s\nWall time: 7min 45s\n"
      }
     ],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}