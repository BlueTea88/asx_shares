{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "3.1.1 Entry Signals - Donchian High"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the Donchian High entry signal and calculate performance statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from itertools import product\n",
    "inlib = '/data/2_dataprep/symboldata'\n",
    "worklib = '/scratch' #Ephemeral directory\n",
    "outlib = '/data/3_entry'\n",
    "symbolList = pd.read_pickle('/data/2_dataprep/symbolList.p')"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Entry Signal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Donchian High entry signal\n",
    "def entry_DonchianHigh(data,p_high,p_pullback,p_days_pullback,\n",
    "                       price,variation):\n",
    "    '''\n",
    "    Outputs a dataset of dates and prices that triggered the Donchian High signal.\n",
    "    \n",
    "    data: dataset containing historical prices for an individual stock\n",
    "    p_high: the number of days used to calculate the Donchian breakout criteria\n",
    "    p_pullback: pullback multiple of variation\n",
    "    p_days_pullback: number of days after the Donchian breakout for the pullback to be effective\n",
    "    price: price measure to consider (eg. adjClose, close)\n",
    "    variation: variation measure used to calculate pullback criteria\n",
    "    '''\n",
    "    temp = data.copy()\n",
    "    temp.sort(['date'],inplace=True)\n",
    "    temp.index = range(temp.shape[0])\n",
    "    temp['entry_date'] = np.nan\n",
    "    temp['entry_price'] = np.nan\n",
    "    temp['entry_'+price] = np.nan\n",
    "    \n",
    "    #Calculate Donchian cutoff\n",
    "    temp['__cutoff'] = pd.rolling_max(temp[price],window=p_high,min_periods=p_high).shift()\n",
    "    \n",
    "    #Loop across dates that meet the Donchian cutoff\n",
    "    for i in temp[(temp[price] > temp['__cutoff'])].index:\n",
    "        #Check if the pullback criteria is met\n",
    "        pullback_criteria = temp.ix[i,price]*(1.0-p_pullback*temp.ix[i,variation])\n",
    "        check_pullback = temp.ix[i:(min(i+p_days_pullback,temp.shape[0]-1))]\n",
    "        check_pullback = check_pullback[check_pullback[price] < pullback_criteria]\n",
    "        if check_pullback.shape[0] > 0:\n",
    "            pullback_i = check_pullback.index[0]\n",
    "            temp.ix[i,'entry_date'] = temp.ix[pullback_i,'date']\n",
    "            temp.ix[i,'entry_price'] = temp.ix[pullback_i,'adjClose']\n",
    "            temp.ix[i,'entry_'+price] = temp.ix[pullback_i,price]\n",
    "    \n",
    "    #Cleanup\n",
    "    temp2 = temp.drop([col for col in temp.columns if col.startswith('__')],axis=1)\n",
    "    temp2 = temp2[temp2['entry_price']>0].drop_duplicates(['entry_date'])\n",
    "    temp2.sort(['entry_date'],inplace=True)\n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the performance of entry signals at various intervals\n",
    "def entryPerformance(data,entry_data,transaction,intervals):\n",
    "    '''\n",
    "    Attaches performance statistics at various intervals to the input entry_data dataset.\n",
    "    \n",
    "    data: dataset containing historical prices for an individual stock\n",
    "    entry_data: dataset containing entry trades for an individual stock\n",
    "    transaction: transaction cost percent for each trade\n",
    "    intervals: list of durations in days to compute performance metrics\n",
    "    '''\n",
    "    temp = entry_data.copy()\n",
    "    tempdata = data[['date','adjClose']].copy()\n",
    "    tempdata.sort(['date'],inplace=True)\n",
    "    tempdata.index = range(tempdata.shape[0])\n",
    "    max_date = tempdata['date'].max() #Latest date available\n",
    "    \n",
    "    #Initialise columns\n",
    "    for j in intervals:\n",
    "        temp['p_MFE_'+str(j)] = np.nan\n",
    "        temp['p_MAE_'+str(j)] = np.nan\n",
    "        temp['p_DER_'+str(j)] = np.nan\n",
    "    if temp.shape[0] == 0: return temp #Returns original dataset if no trades\n",
    "    \n",
    "    #Loop across entry trades and intervals\n",
    "    for i,j in product(temp.index,intervals):\n",
    "        entry_date = temp.ix[i,'entry_date']\n",
    "        entry_price = temp.ix[i,'entry_price']\n",
    "        final_date = entry_date + dt.timedelta(days=j) #Final date for performance evaluation\n",
    "        if final_date > max_date: continue #Skip to the next loop if not enough data\n",
    "        \n",
    "        #Subset data\n",
    "        temp_price = tempdata[(tempdata['date'] > entry_date) &\n",
    "                              (tempdata['date'] <= final_date)]        \n",
    "        if temp_price.shape[0]==0: continue #Prevents errors if there are gaps in data\n",
    "        \n",
    "        #Calculate maximum favourable/adverse execution\n",
    "        highest = temp_price['adjClose'].max()-(transaction*entry_price)\n",
    "        lowest = temp_price['adjClose'].min()-(transaction*entry_price)\n",
    "        temp.ix[i,'p_MFE_'+str(j)] = 365.25*np.log(highest/entry_price)/j\n",
    "        temp.ix[i,'p_MAE_'+str(j)] = 365.25*np.log(lowest/entry_price)/j\n",
    "        \n",
    "        #Calculate duration ending return\n",
    "        ending = temp_price.ix[temp_price.index[-1],'adjClose']-(transaction*entry_price)\n",
    "        temp.ix[i,'p_DER_'+str(j)] = 365.25*np.log(ending/entry_price)/j    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Initialise Parallel Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.parallel import Client\n",
    "rc = Client()\n",
    "l_view = rc.load_balanced_view()\n",
    "d_view = rc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from itertools import product\n",
    "import socket\n",
    "import platform\n",
    "inlib = '/data/2_dataprep/symboldata'\n",
    "worklib = '/scratch' #Ephemeral directory\n",
    "outlib = '/data/3_entry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_view.push({'entry_DonchianHigh':entry_DonchianHigh,'entryPerformance':entryPerformance});\n",
    "for i in rc.ids: #Identify machines\n",
    "    dv = rc[i]\n",
    "    dv.push({'machine_id':i})"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Score Entry Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to score an individual symbol\n",
    "def entryScore(fileloc,symbol,entryFunction,transaction,intervals,outloc,**kwargs):\n",
    "    '''\n",
    "    Outputs triggered entry signals of an individual symbol and associated performance statistics.\n",
    "    \n",
    "    fileloc: location of file that contains the required individual company data\n",
    "    symbol: company to process\n",
    "    entryFunction: entry signal function\n",
    "    transaction: transaction costs as a percentage of each trade\n",
    "    intervals: durations to calculate performance metrics\n",
    "    outloc: location to store final dataset\n",
    "    '''\n",
    "    indata = pd.read_pickle(fileloc) #Read data\n",
    "    data1 = entryFunction(data=indata,**kwargs) #Find triggered entry signals\n",
    "    data2 = entryPerformance(indata,data1,transaction,intervals) #Calculate performance statistics\n",
    "    data2.to_pickle(outloc) #Output final dataset\n",
    "    return machine_id #Check which machine processes this function"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "Donchian High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_DonchianHigh(label,p_high,p_pullback,p_days_pullback,price,variation):    \n",
    "    #Loop across symbols and process in parallel\n",
    "    allResults = []\n",
    "    for i,symbol in enumerate(symbolList):\n",
    "        fileloc = inlib+'/'+symbol+'.p'\n",
    "        asyncResult = l_view.apply(entryScore,\n",
    "                                   fileloc=fileloc,symbol=symbol,\n",
    "                                   entryFunction=entry_DonchianHigh,\n",
    "                                   transaction=0.01,intervals=[50,100,150,200,250,300,350,700,1050],\n",
    "                                   outloc=worklib+'/'+label+'_'+symbol+'.p',\n",
    "                                   p_high=p_high,p_pullback=p_pullback,p_days_pullback=p_days_pullback,\n",
    "                                   price=price,variation=variation)\n",
    "        allResults.append((symbol,asyncResult))        \n",
    "    \n",
    "    #Check results and append final datasets\n",
    "    i = 0\n",
    "    for symbol,result in allResults:\n",
    "        try:\n",
    "            result_test = result.get()\n",
    "            if i==0: \n",
    "                final = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')                \n",
    "            else:\n",
    "                temp = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')\n",
    "                final = final.append(temp)                \n",
    "            i = i + 1\n",
    "            #if i%500 == 0: print i\n",
    "        except:\n",
    "            print 'Error processing symbol: '+symbol\n",
    "            pass\n",
    "    \n",
    "    #Output final dataset\n",
    "    final.to_pickle(outlib+'/'+label+'.p')\n",
    "    print 'Procesed: '+label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#inv_DonchianHigh('DonchianHigh_350_0_30',350,0,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_0_30',300,0,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_250_0_30',250,0,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_200_0_30',200,0,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_150_0_30',150,0,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_350_3_30',350,3,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_3_30',300,3,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_3_30_close',300,3,30,'close','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_250_3_30',250,3,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_200_3_30',200,3,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_150_3_30',150,3,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_350_3_60',350,3,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_3_60',300,3,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_250_3_60',250,3,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_200_3_60',200,3,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_150_3_60',150,3,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_350_5_30',350,5,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_5_30',300,5,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_250_5_30',250,5,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_200_5_30',200,5,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_150_5_30',150,5,30,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_350_5_60',350,5,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_300_5_60',300,5,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_250_5_60',250,5,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_200_5_60',200,5,60,'adjClose','z_varclose_avg30')\n",
    "#inv_DonchianHigh('DonchianHigh_150_5_60',150,5,60,'adjClose','z_varclose_avg30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "name": "3.1.1_Entry_DonchianHigh"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}