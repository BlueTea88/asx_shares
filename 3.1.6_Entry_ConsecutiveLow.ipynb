{
 "metadata": {
  "name": "3.1.6_Entry_ConsecutiveLow"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "3.1.6 Entry Signals - Consecutive Low"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Simulate the Consecutive Low entry signal."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#cp /data/2_dataprep/symboldata/* /scratch\n#chmod 777 /scratch",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom itertools import product\n#inlib = '/data/2_dataprep/symboldata'\ninlib = '/scratch'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/3_entry'\nsymbolList = pd.read_pickle('/data/2_dataprep/symbolList.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Entry Signal Functions"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Consecutive Low entry signal\ndef entry_ConsecutiveLow(data,p_days,price):\n    '''\n    Outputs a dataset of dates and prices that triggered the Consecutive Low signal.\n    \n    data: dataset containing historical prices for an individual stock\n    p_days: number of consecutive lower prices before the signal is triggered\n    price: price measure to consider (eg. adjClose, close)\n    '''\n    temp = data.copy()\n    temp.sort(['date'],inplace=True)\n    temp.index = range(temp.shape[0])\n    temp['entry_date'] = np.nan\n    temp['entry_price'] = np.nan\n    temp['entry_'+price] = np.nan\n    \n    # Create flag to indicate a lower price\n    temp['__flag'] = (temp[price] < temp[price].shift())*1\n    \n    # Count consecutive positive values - not that efficient\n    temp['__consecutive'] = 0\n    counter = 0 #keep track of consecutive values\n    for i in range(len(temp)):\n        if temp.ix[i,'__flag'] == 1:\n            counter = counter + 1\n        else:\n            counter = 0\n        temp.ix[i,'__consecutive'] = counter\n    \n    # Use the closing price of the following day as the entry price\n    temp['__trigger'] = (temp['__consecutive'].shift() == p_days)\n    temp2 = temp[temp['__trigger']]\n    temp2['entry_date'] = temp2['date']\n    temp2['entry_price'] = temp2['adjClose']\n    temp2['entry_'+price] = temp2[price]\n    \n    #Cleanup    \n    temp2 = temp2.drop([col for col in temp.columns if col.startswith('__')],axis=1)\n    temp2.sort(['entry_date'],inplace=True)\n    return temp2",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Calculate the performance of entry signals at various intervals\ndef entryPerformance(data,entry_data,transaction,intervals,shortsell):\n    '''\n    Attaches performance statistics at various intervals to the input entry_data dataset.\n    \n    data: dataset containing historical prices for an individual stock\n    entry_data: dataset containing entry trades for an individual stock\n    transaction: transaction cost percent for each trade\n    intervals: list of durations in days to compute performance metrics\n    shortsell: specifies whether to add or subtract transaction costs\n    '''\n    temp = entry_data.copy()\n    tempdata = data[['date','adjClose']].copy()\n    tempdata.sort(['date'],inplace=True)\n    tempdata.index = range(tempdata.shape[0])\n    max_date = tempdata['date'].max() #Latest date available\n    \n    #Add transaction costs if short-selling (negative returns are better)\n    if shortsell: \n        transaction_cost = -transaction\n    else:\n        transaction_cost = transaction\n    \n    #Initialise columns\n    for j in intervals:\n        temp['p_MFE_'+str(j)] = np.nan\n        temp['p_MAE_'+str(j)] = np.nan\n        temp['p_DER_'+str(j)] = np.nan\n    if temp.shape[0] == 0: return temp #Returns original dataset if no trades\n    \n    #Loop across entry trades and intervals\n    for i,j in product(temp.index,intervals):\n        entry_date = temp.ix[i,'entry_date']\n        entry_price = temp.ix[i,'entry_price']\n        final_date = entry_date + dt.timedelta(days=j) #Final date for performance evaluation\n        if final_date > max_date: continue #Skip to the next loop if not enough data\n        \n        #Subset data\n        temp_price = tempdata[(tempdata['date'] > entry_date) &\n                              (tempdata['date'] <= final_date)]        \n        if temp_price.shape[0]==0: continue #Prevents errors if there are gaps in data\n        \n        #Calculate maximum favourable/adverse execution\n        highest = temp_price['adjClose'].max()-(transaction_cost*entry_price)\n        lowest = temp_price['adjClose'].min()-(transaction_cost*entry_price)\n        temp.ix[i,'p_MFE_'+str(j)] = 365.25*np.log(highest/entry_price)/j\n        temp.ix[i,'p_MAE_'+str(j)] = 365.25*np.log(lowest/entry_price)/j\n        \n        #Calculate duration ending return\n        ending = temp_price.ix[temp_price.index[-1],'adjClose']-(transaction_cost*entry_price)\n        temp.ix[i,'p_DER_'+str(j)] = 365.25*np.log(ending/entry_price)/j    \n    return temp        ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Initialise Parallel Processing"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from IPython.parallel import Client\nrc = Client()\nl_view = rc.load_balanced_view()\nd_view = rc[:]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%px\nimport pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom itertools import product\nimport socket\nimport platform\n#inlib = '/data/2_dataprep/symboldata'\ninlib = '/scratch'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/3_entry'",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "d_view.push({'entry_ConsecutiveLow':entry_ConsecutiveLow,'entryPerformance':entryPerformance});\nfor i in rc.ids: #Identify machines\n    dv = rc[i]\n    dv.push({'machine_id':i})",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Score Entry Signals"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Function to score an individual symbol\ndef entryScore(fileloc,symbol,entryFunction,transaction,intervals,shortsell,outloc,**kwargs):\n    '''\n    Outputs triggered entry signals of an individual symbol and associated performance statistics.\n    \n    fileloc: location of file that contains the required individual company data\n    symbol: company to process\n    entryFunction: entry signal function\n    transaction: transaction costs as a percentage of each trade\n    intervals: durations to calculate performance metrics\n    outloc: location to store final dataset\n    '''\n    indata = pd.read_pickle(fileloc) #Read data\n    data1 = entryFunction(data=indata,**kwargs) #Find triggered entry signals\n    data2 = entryPerformance(indata,data1,transaction,intervals,shortsell) #Calculate performance statistics\n    data2.to_pickle(outloc) #Output final dataset\n    return machine_id #Check which machine processes this function",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Consecutive Low"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def inv_ConsecutiveLow(label,p_days,price,shortsell):\n    #Loop across symbols and process in parallel\n    allResults = []\n    for i,symbol in enumerate(symbolList):\n        fileloc = inlib+'/'+symbol+'.p'\n        asyncResult = l_view.apply(entryScore,\n                                   fileloc=fileloc,symbol=symbol,\n                                   entryFunction=entry_ConsecutiveLow,\n                                   transaction=0.005,intervals=[5,10,15,20,30,40,50,60],\n                                   shortsell=shortsell,\n                                   outloc=worklib+'/'+label+'_'+symbol+'.p',\n                                   p_days=p_days,price=price)\n        allResults.append((symbol,asyncResult))        \n    \n    #Check results and append final datasets\n    i = 0\n    for symbol,result in allResults:\n        try:\n            result_test = result.get()\n            if i==0: \n                final = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')                \n            else:\n                temp = pd.read_pickle(worklib+'/'+label+'_'+symbol+'.p')\n                final = final.append(temp)                \n            i = i + 1\n            #if i%500 == 0: print i\n        except:\n            print 'Error processing symbol: '+symbol\n            pass\n    \n    #Output final dataset\n    final.to_pickle(outlib+'/'+label+'.p')\n    print 'Procesed: '+label",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\ninv_ConsecutiveLow('ConsecutiveLow_4_close',4,'close',False)\ninv_ConsecutiveLow('ConsecutiveLow_5_close',5,'close',False)\ninv_ConsecutiveLow('ConsecutiveLow_6_close',6,'close',False)\ninv_ConsecutiveLow('ConsecutiveLow_7_close',7,'close',False)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}