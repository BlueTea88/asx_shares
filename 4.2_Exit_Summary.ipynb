{
 "metadata": {
  "name": "4.2_Exit_Summary"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "4.2 Exit Signals - Summary"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Summarise the statistics of fitted exit signals."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd\nimport numpy as np\nimport datetime as dt\nfrom itertools import product\ninlib = '/data/2_dataprep/symboldata'\nentrylib = '/data/3_entry'\nworklib = '/scratch' #Ephemeral directory\noutlib = '/data/4_exit'\nsymbolList = pd.read_pickle('/data/2_dataprep/symbolList.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Summarise Exit Performance"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Function to summarise exit performance\ndef exitSummary(exit_data,transaction,volume_cutoff,volume,volume_rank,shortsell):\n    '''\n    Summarises the performance statistics of exited trades.\n        \n    exit_data: dataset of trades with exit signals\n    transaction: transaction cost as a percentage of trades\n    volume_cutoff: specifies the minimum volume cut-off\n    volume: specifies the volume column name\n    volume_rank: specifies the volume rank column name\n    shortsell: specifies whether transaction cost should be added or removed\n    '''\n    temp = exit_data.copy()\n    temp = temp[temp[volume]>=volume_cutoff] #Remove trades that do not meet the volume cutoff\n    temp.sort(['symbol','entry_date'],inplace=True)\n    temp.index = range(temp.shape[0])\n    \n    #Filter for non-overlapping trades\n    temp['include'] = False\n    ret_date = temp.ix[0,'entry_date'] - dt.timedelta(days=1)\n    ret_symbol = temp.ix[0,'symbol']\n    for i in temp.index:\n        if (temp.ix[i,'symbol'] != ret_symbol):\n            ret_date = temp.ix[i,'entry_date'] - dt.timedelta(days=1)\n            ret_symbol = temp.ix[i,'symbol']\n        if (temp.ix[i,'entry_date'] > ret_date):\n            temp.ix[i,'include'] = True\n            ret_date = temp.ix[i,'exit_date']\n    temp = temp[temp['include']]\n    \n    #Calculations\n    if shortsell:\n        temp['return'] = np.log((temp['exit_price']/temp['entry_price'])+transaction)\n    else:\n        temp['return'] = np.log((temp['exit_price']/temp['entry_price'])-transaction)\n    temp['duration'] = (temp['exit_date']-temp['entry_date']+dt.timedelta(days=1))\n    temp['duration'] = temp['duration'].map(lambda x: x/np.timedelta64(1,'D'))\n    temp['volume_rank_50'] = temp[volume_rank].map(lambda x: math.floor((x/50+1)*50))\n    temp['quarter'] = temp['entry_date'].map(lambda x: str(x.year)+'_'+str(x.quarter))\n    temp['positive_return'] = (temp['return']>0)\n    temp['count'] = 1.0\n    \n    #Summarise data\n    temp = temp[['GICS','volume_rank_50','quarter','positive_return',\n                 'return','duration','count']]\n    sumgroup = temp.groupby(['GICS','volume_rank_50','quarter','positive_return'])\n    summary = sumgroup[['return','duration','count']].sum()\n    summary.reset_index(inplace=True)\n    return summary",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Additional Processes"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Process to combine exit signals\ndef exit_Combine(exit_datasets):\n    '''\n    Combine exit signals from multiple datasets - the earliest exit signal will be used.\n    \n    exit_datasets: dataset containing exit signal information.\n    '''\n    #Create temporary copies of exit datasets\n    t_exits = []\n    for t_exit in exit_datasets:\n        t_exits.append(t_exit.copy())\n    \n    #Prepare data\n    for i,t_exit in enumerate(t_exits):\n        #Sort and reindex\n        t_exit.sort(['symbol','entry_date','date'],inplace=True)\n        t_exit.index = range(t_exit.shape[0])\n        \n        #Create temporary dataset to determine earliest exit signal\n        t_date = t_exit[['symbol','entry_date','date','exit_date']].copy()\n        t_date.rename(columns={'exit_date':'exit_date_'+str(i)},inplace=True)\n        \n        #Merge exit dates\n        if i==0: t_dates = t_date\n        else: t_dates = pd.merge(t_dates,t_date,how='outer',on=['symbol','entry_date','date'])\n    \n    #Error trap missing dates\n    for i in range(len(t_exits)):\n        if t_dates[t_dates['exit_date_'+str(i)].map(lambda x: pd.isnull(x))].shape[0]!=0:\n            raise ValueError('exit date missing for data '+str(i))\n    \n    #Map exit signal with earliest exit date\n    date_cols = ['exit_date_'+str(i) for i in range(len(exit_datasets))]\n    t_dates['earliest_exit'] = t_dates[date_cols].apply(lambda x: np.argmin(x),axis=1)\n    \n    #Filter for earliest exits and append datasets\n    for i,t_exit in enumerate(t_exits):\n        t_exit2 = t_exit[t_dates['earliest_exit'].map(lambda x: x==i)]\n        if i==0: temp = t_exit2.copy()\n        else: temp = temp.append(t_exit2)\n            \n    #Cleanup\n    temp.sort(['symbol','entry_date','date'],inplace=True)\n    if np.sum(temp.duplicated(cols=['symbol','entry_date']))!=0:\n        raise ValueError('duplicated data')\n    if temp.shape[0] != t_exits[0].shape[0]:\n        raise ValueError('final number of obs does not match')            \n    return temp",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Duration Stop"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#List exit specifications of simulated initial and duration stops\nexit_initial = ['InitialStop_0_7_7',\n                'InitialStop_0_10_10',\n                'InitialStop_0_15_15',\n                'InitialStop_5_5_15',\n                'InitialStop_7_5_15',                \n                'InitialStop_10_5_15']\n\nexit_duration = ['DurationStop_50',\n                 'DurationStop_100',\n                 'DurationStop_150',\n                 'DurationStop_200',\n                 'DurationStop_250',\n                 'DurationStop_300',\n                 'DurationStop_350',\n                 'DurationStop_400']",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian High"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianHigh_300_3_30_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_duration = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_duration+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_duration])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_duration'] = p_duration\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 7min 37s, sys: 816 ms, total: 7min 38s\nWall time: 7min 38s\n"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_duration.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_duration.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianHigh_300_3_30_close_duration.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianHigh_300_3_30_close_duration.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian Low"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianLow_300_3_30_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_duration = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_duration+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_duration])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',True)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_duration'] = p_duration\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 4min 51s, sys: 880 ms, total: 4min 52s\nWall time: 4min 54s\n"
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_duration.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_duration.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianLow_300_3_30_close_duration.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianLow_300_3_30_close_duration.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Force Index"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'Force2_233_0p4_1_1_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_duration = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_duration+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_duration])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',True)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_duration'] = p_duration\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_duration in product(exit_initial,exit_duration): \n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_duration+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_duration.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_duration.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_Force2_233_0p4_1_1_close_duration.csv \n#/shares/models/phase_2/data/4_exit/summary_Force2_233_0p4_1_1_close_duration.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Trailing Stop"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#List exit specifications of simulated initial and trailing stops\nexit_initial = ['InitialStop_0_7_7',\n                'InitialStop_0_10_10',\n                'InitialStop_0_15_15',\n                'InitialStop_5_5_15',\n                'InitialStop_7_5_15',                \n                'InitialStop_10_5_15']\n\nexit_trail = ['TrailStop_0_7_7',\n              'TrailStop_0_10_10',\n              'TrailStop_0_15_15',\n              'TrailStop_5_5_15',\n              'TrailStop_7_5_15',                \n              'TrailStop_10_5_15']",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian High"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianHigh_300_3_30_close'\n\n#Combine trailing stops with the same initial stop specifications\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_trail = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_trail+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_trail])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_trail'] = p_trail\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 53.1 s, sys: 272 ms, total: 53.3 s\nWall time: 54.2 s\n"
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_trail.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_trail.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianHigh_300_3_30_close_trail.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianHigh_300_3_30_close_trail.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian Low"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianLow_300_3_30_close'\n\n#Combine trailing stops with the same initial stop specifications\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_trail = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_trail+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_trail])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_trail'] = p_trail\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 36.7 s, sys: 164 ms, total: 36.9 s\nWall time: 37.6 s\n"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_trail.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_trail.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianLow_300_3_30_close_trail.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianLow_300_3_30_close_trail.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Force Index"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'Force2_233_0p4_1_1_close'\n\n#Combine trailing stops with the same initial stop specifications\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_trail = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_trail+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_trail])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_trail'] = p_trail\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_trail in exit_trail: \n    p_initial = 'InitialStop'+p_trail[9:]\n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_trail+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_trail.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_trail.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_Force2_233_0p4_1_1_close_trail.csv \n#/shares/models/phase_2/data/4_exit/summary_Force2_233_0p4_1_1_close_trail.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Inactive Stop"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#List exit specifications of simulated initial and inactive stops\nexit_initial = ['InitialStop_0_7_7',\n                'InitialStop_0_10_10',\n                'InitialStop_0_15_15',\n                'InitialStop_5_5_15',\n                'InitialStop_7_5_15',                \n                'InitialStop_10_5_15']\n\nexit_inactive = ['InactiveStop_20',\n                 'InactiveStop_35',\n                 'InactiveStop_50',\n                 'InactiveStop_80']",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian High"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianHigh_300_3_30_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_inactive = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_inactive+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_inactive])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_inactive'] = p_inactive\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 3min 17s, sys: 728 ms, total: 3min 18s\nWall time: 3min 18s\n"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_inactive.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_inactive.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianHigh_300_3_30_close_inactive.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianHigh_300_3_30_close_inactive.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Force Index"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'Force2_233_0p4_1_1_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_inactive = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_inactive+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_inactive])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_inactive'] = p_inactive\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_inactive.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_inactive.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_Force2_233_0p4_1_1_close_inactive.csv \n#/shares/models/phase_2/data/4_exit/summary_Force2_233_0p4_1_1_close_inactive.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Inactive Trail Stop"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#List exit specifications of simulated initial and inactive stops\nexit_initial = ['InitialStop_0_7_7',\n                'InitialStop_0_10_10',\n                'InitialStop_0_15_15',\n                'InitialStop_5_5_15',\n                'InitialStop_7_5_15',                \n                'InitialStop_10_5_15']\n\nexit_inactive = ['InactiveStop_20',\n                 'InactiveStop_35',\n                 'InactiveStop_50',\n                 'InactiveStop_80']\n\nexit_trail = ['TrailStop_0_7_7',\n              'TrailStop_0_10_10',\n              'TrailStop_0_15_15',\n              'TrailStop_5_5_15',\n              'TrailStop_7_5_15',                \n              'TrailStop_10_5_15']",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Donchian High"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'DonchianHigh_300_3_30_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    \n    p_trail = 'TrailStop'+p_initial[11:]\n    \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_inactive = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_inactive+'.p')\n    e_trail = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_trail+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_inactive,e_trail])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_inactive'] = p_inactive\n    e_summary['exit_signal_trail'] = p_trail\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_trail+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "CPU times: user 4min 53s, sys: 700 ms, total: 4min 54s\nWall time: 4min 54s\n"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    p_trail = 'TrailStop'+p_initial[11:]\n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_trail+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_inactive_trail.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_inactive_trail.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_DonchianHigh_300_3_30_close_inactive_trail.csv \n#/shares/models/phase_2/data/4_exit/summary_DonchianHigh_300_3_30_close_inactive_trail.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Force Index"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nentry_signal = 'Force2_233_0p4_1_1_close'\n\n#Loop across combinations of exit signals for processing\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    \n    p_trail = 'TrailStop'+p_initial[11:]\n    \n    e_initial = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_initial+'.p')\n    e_inactive = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_inactive+'.p')\n    e_trail = pd.read_pickle(outlib+'/'+entry_signal+'_'+p_trail+'.p')\n    \n    #Combine exit datasets\n    e_all = exit_Combine([e_initial,e_inactive,e_trail])\n    \n    #Summarise performance\n    e_summary = exitSummary(e_all,0.01,80000,'z_vol_avg30','z_volrank_avg30',False)\n    e_summary['entry_signal'] = entry_signal\n    e_summary['exit_signal_initial'] = p_initial\n    e_summary['exit_signal_inactive'] = p_inactive\n    e_summary['exit_signal_trail'] = p_trail\n    e_summary.to_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_trail+'_'+p_initial+'.p')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Combine summarised data\ni = 0\nfor p_initial,p_inactive in product(exit_initial,exit_inactive): \n    p_trail = 'TrailStop'+p_initial[11:]\n    e_summary = pd.read_pickle(outlib+'/sum_'+entry_signal+'_'+p_inactive+'_'+p_trail+'_'+p_initial+'.p')\n    if i==0: final_summary = e_summary.copy()\n    else: final_summary = final_summary.append(e_summary)\n    i = i+1\n    final_summary.to_pickle(outlib+'/summary_'+entry_signal+'_inactive_trail.p')\n    final_summary.to_csv(outlib+'/summary_'+entry_signal+'_inactive_trail.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Download the summarised csv file\n#starcluster get testcluster /data/4_exit/summary_Force2_233_0p4_1_1_close_inactive_trail.csv \n#/shares/models/phase_2/data/4_exit/summary_Force2_233_0p4_1_1_close_inactive_trail.csv",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}